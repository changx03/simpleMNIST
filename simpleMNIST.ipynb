{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUP8PRZ8Vlgh2BcUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22beccac208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "m = 50000 n =  784\n"
     ]
    }
   ],
   "source": [
    "# Get size for training, development (validation), test sets\n",
    "print(X_train.shape)\n",
    "m = X_train.shape[0]  # num of training images\n",
    "n = X_train.shape[1] * X_train.shape[1]  # num of features in 1 image\n",
    "c = 10 # output has 10 classes\n",
    "print('m =', m, 'n = ', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flatten traingin and test images\n",
    "def flattenRawData(rawData):\n",
    "    return rawData.reshape((rawData.shape[0], -1))\n",
    "\n",
    "X_train_flat = flattenRawData(X_train)\n",
    "X_val_flat = flattenRawData(X_val)\n",
    "X_test_flat =flattenRawData(X_test)\n",
    "\n",
    "# The grayscale images do not require normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_flat.shape =  (50000, 784)\n",
      "X_val_flat.shape =  (10000, 784)\n",
      "X_test_flat.shape =  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Testing bolck \n",
    "print('X_train_flat.shape = ', X_train_flat.shape)\n",
    "print('X_val_flat.shape = ', X_val_flat.shape)\n",
    "print('X_test_flat.shape = ', X_test_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using one hot encoding to generate a m(# of samples) x c(# of classes) matrix\n",
    "# eg: when c = 3, [[0],[1],[2]] becomes [[1,0,0],[0,1,0],[0,0,1]]\n",
    "def oneHotMatrix(y, C):\n",
    "    C = tf.constant(C)\n",
    "    oneHotMat = tf.one_hot(y, C, axis=1)\n",
    "    sess = tf.Session()\n",
    "    one_hot = sess.run(oneHotMat)\n",
    "    sess.close()\n",
    "    return np.squeeze(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_hot.shape =  (50000, 10)\n",
      "y_train[5] =  2\n",
      "y_train_hot[5,:] =  [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Testing bolck \n",
    "y_train_hot = oneHotMatrix(y_train, c)\n",
    "y_val_hot = oneHotMatrix(y_val, c)\n",
    "y_test_hot = oneHotMatrix(y_test, c)\n",
    "print('y_train_hot.shape = ', y_train_hot.shape)\n",
    "print('y_train[5] = ', y_train[5])\n",
    "print('y_train_hot[5,:] = ', str(y_train_hot[5,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Tensors: initializing parameters and creating placeholders\n",
    "def createPlaceHolders(n, c):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, c))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Testing bolck \n",
    "X, Y = createPlaceHolders(n, c)\n",
    "print ('X = ' + str(X))\n",
    "print ('Y = ' + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize 2 hidden layers\n",
    "def initParameters(n, n_h1, n_h2, c):\n",
    "    tf.set_random_seed(1)\n",
    "    W1 = tf.get_variable('W1', [n, n_h1], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable('b1', [1, n_h1], initializer= tf.zeros_initializer())\n",
    "    W2 = tf.get_variable('W2', [n_h1, n_h2], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable('b2', [1, n_h2], initializer= tf.zeros_initializer())\n",
    "    W3 = tf.get_variable('W3', [n_h2, c], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable('b3', [1, c], initializer= tf.zeros_initializer())\n",
    "    return {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2, 'W3': W3, 'b3': b3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(784, 64) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(1, 64) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(64, 32) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(1, 32) dtype=float32_ref>\n",
      "W3 = <tf.Variable 'W3:0' shape=(32, 10) dtype=float32_ref>\n",
      "b3 = <tf.Variable 'b3:0' shape=(1, 10) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# Testing bolck \n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initParameters(n, 64, 32, c)\n",
    "    print('W1 = ' + str(parameters['W1']))\n",
    "    print('b1 = ' + str(parameters['b1']))\n",
    "    print('W2 = ' + str(parameters['W2']))\n",
    "    print('b2 = ' + str(parameters['b2']))\n",
    "    print('W3 = ' + str(parameters['W3']))\n",
    "    print('b3 = ' + str(parameters['b3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Activation function can be sigmoid or ReLu\n",
    "def forwardProp(X, parameters, method = 'relu'):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    Z1 = tf.add(tf.matmul(X, W1), b1)\n",
    "    if method == 'relu':\n",
    "        A1 = tf.nn.relu(Z1)\n",
    "    else:\n",
    "        A1 = tf.nn.sigmoid(Z1)\n",
    "    Z2 = tf.add(tf.matmul(A1, W2), b2)\n",
    "    if method == 'relu':\n",
    "        A2 = tf.nn.relu(Z2)\n",
    "    else:\n",
    "        A2 = tf.nn.sigmoid(Z2)\n",
    "    Z3 = tf.add(tf.matmul(A2, W3), b3)\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeCost(Z, Y):\n",
    "#     print('Z.shape=', Z.shape)\n",
    "#     print('Y.shape=', Y.shape)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z, labels=Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost =  Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Testing bolck \n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X, Y = createPlaceHolders(n, c)\n",
    "    parameters = initParameters(n, 64, 32, c)\n",
    "    Z = forwardProp(X, parameters)\n",
    "    cost = computeCost(Z, Y)\n",
    "    print('cost = ', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate mini batches\n",
    "def genMiniBatch(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    # TODO: 1 shuffle, 2 partition, 3 handle the leftover\n",
    "    m = X.shape[0]    # # of training samples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)    # reset RNG\n",
    "    \n",
    "    # shuffle\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation, :]\n",
    "    shuffled_Y = Y[permutation, :] # ??? .reshape((m, Y.shape[1])) \n",
    "    \n",
    "    # partition\n",
    "    num_full_batches = int(np.floor(m/mini_batch_size))\n",
    "    for i in range(0, num_full_batches):\n",
    "        mini_batch_X = shuffled_X[i*mini_batch_size : i*mini_batch_size+mini_batch_size, :]\n",
    "        mini_batch_Y = shuffled_Y[i*mini_batch_size : i*mini_batch_size+mini_batch_size, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # attach the leftover at the ned\n",
    "    if m % mini_batch_size !=0:\n",
    "        mini_batch_X = shuffled_X[num_full_batches * mini_batch_size : m, :]\n",
    "        mini_batch_Y = shuffled_Y[num_full_batches * mini_batch_size : m, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawPlot(data, x_label, y_label, title):\n",
    "    plt.plot(np.squeeze(data))\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_dev, Y_dev, \n",
    "          n_hidden1=64, n_hidden2=32, learning_rate=0.01, decay_rate=0.96, num_epochs=500, minibatch_size=128):\n",
    "    ops.reset_default_graph()\n",
    "    tf.set_random_seed(1)\n",
    "    (m, n) = X_train.shape\n",
    "    c = Y_train.shape[1]\n",
    "    print('m = ', m, 'n = ', n, 'c = ', c)\n",
    "    costs = []\n",
    "    learning_rates = []\n",
    "    seed = 1\n",
    "    num_minibatches = int(m/minibatch_size)\n",
    "    \n",
    "    # initialization\n",
    "    X, Y = createPlaceHolders(n, c)\n",
    "    parameters = initParameters(n, n_hidden1, n_hidden2, c)\n",
    "    \n",
    "    # forward propagation\n",
    "    Z = forwardProp(X, parameters)\n",
    "    # update cost\n",
    "    cost = computeCost(Z, Y)\n",
    "    \n",
    "    # ues learning rate decay\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    adapt_learning_rate = tf.train.natural_exp_decay(learning_rate, global_step, num_minibatches*20, decay_rate)\n",
    "    \n",
    "    # back propagation\n",
    "    optimizer = tf.train.AdamOptimizer(adapt_learning_rate).minimize(cost, global_step=global_step)    \n",
    "        \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0.0\n",
    "            seed += 1\n",
    "            minibatches = genMiniBatch(X_train, Y_train, minibatch_size, seed)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                (mini_X, mini_Y) = minibatch\n",
    "                _ , mini_cost = sess.run([optimizer, cost], feed_dict={X: mini_X, Y: mini_Y})\n",
    "                epoch_cost += mini_cost / num_minibatches\n",
    "                \n",
    "            # print accuracy for dev set\n",
    "            if epoch % 20 == 0:\n",
    "                print (\"Cost after epoch %i: %f, Learning_rate = %f\" % (epoch, epoch_cost, adapt_learning_rate.eval()))\n",
    "            costs.append(epoch_cost)\n",
    "            learning_rates.append(adapt_learning_rate.eval())\n",
    "            \n",
    "            if epoch_cost < 1.0e-6:\n",
    "                break\n",
    "        \n",
    "        # plot cost\n",
    "        drawPlot(costs, 'iterations', 'cost', 'Cost vs. Iteration')\n",
    "        \n",
    "        # plot learning rate\n",
    "        drawPlot(learning_rates, 'iterations', 'Learning rate', 'Larning rate vs. Iteration')\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(Z, axis=1), tf.argmax(Y, axis=1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_dev, Y: Y_dev}))\n",
    "        \n",
    "        parameters = sess.run(parameters)\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m =  50000 n =  784 c =  10\n",
      "Cost after epoch 0: 0.246226, Learning_rate = 0.009530\n",
      "Cost after epoch 20: 0.007543, Learning_rate = 0.003640\n",
      "Cost after epoch 40: 0.000007, Learning_rate = 0.001390\n",
      "Cost after epoch 60: 0.000001, Learning_rate = 0.000531\n",
      "Cost after epoch 80: 0.000000, Learning_rate = 0.000203\n",
      "Cost after epoch 100: 0.000000, Learning_rate = 0.000077\n",
      "Cost after epoch 120: 0.000000, Learning_rate = 0.000030\n",
      "Cost after epoch 140: 0.000000, Learning_rate = 0.000011\n",
      "Cost after epoch 160: 0.000000, Learning_rate = 0.000004\n",
      "Cost after epoch 180: 0.000000, Learning_rate = 0.000002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-0a87f5c8f25a>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, Y_train, X_dev, Y_dev, n_hidden1, n_hidden2, learning_rate, decay_rate, num_epochs, minibatch_size)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mminibatches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mmini_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_Y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                 \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmini_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmini_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmini_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m                 \u001b[0mepoch_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmini_cost\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_minibatches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "parameters = model(X_train_flat, y_train_hot, X_val_flat, y_val_hot, n_hidden1=128, n_hidden2=64, num_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Dev Accuracy: 0.9793\n",
      "Test Accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "# show overall performance\n",
    "XT, YT = createPlaceHolders(n, c)\n",
    "Z = forwardProp(XT, parameters)\n",
    "correct_prediction = tf.cast(tf.equal(tf.argmax(Z, axis=1), tf.argmax(YT, axis=1)), tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    acc = sess.run(accuracy, feed_dict = {XT: X_train_flat, YT: y_train_hot})\n",
    "    print (\"Train Accuracy:\", acc)\n",
    "    acc = sess.run(accuracy, feed_dict = {XT: X_val_flat, YT: y_val_hot})\n",
    "    print (\"Dev Accuracy:\", acc)\n",
    "    acc = sess.run(accuracy, feed_dict = {XT: X_test_flat, YT: y_test_hot})\n",
    "    print (\"Test Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass raw image and raw label for prediction\n",
    "def predictRawImage(img, parameters, y):\n",
    "    x = img.reshape((1, img.shape[0]* img.shape[1]))\n",
    "    XT, YT = createPlaceHolders(n, c)\n",
    "    y_hat = forwardProp(XT, parameters)\n",
    "    predict = tf.argmax(y_hat, axis=1)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "            y_predict = sess.run(predict, feed_dict={XT: x})\n",
    "            print(\"The prediction is %i, the label is %s\" % (np.squeeze(y_predict), str(y)))\n",
    "\n",
    "    %matplotlib inline\n",
    "    plt.imshow(img, cmap=\"Greys\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing block\n",
    "index = 666\n",
    "predictRawImage(X_test[index, :], parameters, y_test[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
